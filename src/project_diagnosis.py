# src/project_diagnosis.py - é¡¹ç›®è¯Šæ–­
import jieba
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import pandas as pd

def extract_keywords(text, top_n=10):
    """æå–å…³é”®è¯ï¼ˆTF-IDF + è¯é¢‘ï¼‰"""
    # ç²¾ç¡®æ¨¡å¼åˆ†è¯
    words = list(jieba.cut(text))
    
    # è¿‡æ»¤åœç”¨è¯ï¼ˆç®€å•ç‰ˆï¼‰
    stopwords = {"çš„", "äº†", "å’Œ", "æ˜¯", "åœ¨", "æœ‰", "æˆ‘", "ä½ ", "ä»–", "å®ƒ", "ä»¬"}
    keywords = [w for w in words if len(w) > 1 and w not in stopwords and not w.isdigit()]
    
    # ç»Ÿè®¡è¯é¢‘
    from collections import Counter
    word_counts = Counter(keywords)
    return [w for w, _ in word_counts.most_common(top_n)]

def diagnose_project(project_text, df):
    """
    è¯Šæ–­é¡¹ç›®ï¼šä¸ä¸€ç­‰å¥–é¡¹ç›®å¯¹æ¯”
    project_text: ç”¨æˆ·è¾“å…¥çš„é¡¹ç›®æè¿°
    df: æ¸…æ´—åçš„æ•°æ®æ¡†
    """
    if len(project_text) < 10:
        return {"error": "é¡¹ç›®æè¿°å¤ªçŸ­"}
    
    # è·å–ä¸€ç­‰å¥–é¡¹ç›®æè¿°
    high_score_projects = df[df["è·å¥–ç­‰çº§"] == "ä¸€ç­‰å¥–"]["é¡¹ç›®åç§°"].tolist()
    if not high_score_projects:
        high_score_projects = ["äººå·¥æ™ºèƒ½åˆ›æ–°é¡¹ç›®", "åŒºå—é“¾åº”ç”¨å¹³å°"]  # å¤‡ç”¨æ¨¡æ¿
    
    # TF-IDFå‘é‡åŒ–
    try:
        vectorizer = TfidfVectorizer(tokenizer=jieba.cut, max_features=100)
        corpus = high_score_projects + [project_text]
        tfidf_matrix = vectorizer.fit_transform(corpus)
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarities = cosine_similarity(
            tfidf_matrix[-1],  # å½“å‰é¡¹ç›®
            tfidf_matrix[:-1]  # é«˜åˆ†é¡¹ç›®
        )
        avg_similarity = float(np.mean(similarities))
    except:
        avg_similarity = 0.5
    
    # ç”Ÿæˆå»ºè®®
    if avg_similarity > 0.6:
        suggestion = "âœ… é¡¹ç›®åˆ›æ–°ç‚¹ä¸é«˜åˆ†é¡¹ç›®ç›¸ä¼¼åº¦è¾ƒé«˜ï¼å»ºè®®çªå‡ºå·®å¼‚åŒ–ç«äº‰ä¼˜åŠ¿"
        risk = "âš ï¸ é¿å…ä¸ç°æœ‰é¡¹ç›®åŒè´¨åŒ–"
    elif avg_similarity > 0.4:
        suggestion = "â­ é¡¹ç›®æœ‰ä¸€å®šåˆ›æ–°æ€§ã€‚å»ºè®®åŠ å¼ºæŠ€æœ¯æ·±åº¦å’Œå¸‚åœºæ•°æ®æ”¯æ’‘"
        risk = "ğŸ“Š è¡¥å……å¸‚åœºè§„æ¨¡ã€ç”¨æˆ·è°ƒç ”ç­‰é‡åŒ–åˆ†æ"
    else:
        suggestion = "ğŸ’¡ é¡¹ç›®å·®å¼‚åŒ–æ˜æ˜¾ã€‚å»ºè®®å‚è€ƒé«˜åˆ†é¡¹ç›®çš„é€»è¾‘ç»“æ„å’Œè¡¨è¾¾æ–¹å¼"
        risk = "ğŸ“ ä¼˜åŒ–å•†ä¸šè®¡åˆ’ä¹¦æ’°å†™è§„èŒƒ"
    
    return {
        "ç›¸ä¼¼åº¦": round(avg_similarity, 2),
        "å»ºè®®": suggestion,
        "é£é™©æç¤º": risk,
        "å…³é”®è¯": extract_keywords(project_text, 8)
    }